---
layout: post
tags: 推荐算法
---

FM可以用在推荐系统中, 作用是将特征交叉考虑到模型中。和在LR前做特征交叉相比, FM的优势主要是在性能上。还是以LR为例, 假如要做完整的二阶特征交叉, 那么LR的模型参数会比没有特征交叉时增加$$m(m-1)/2$$个, 但如果是用FM, 增加的项是$$\sum_i^n \sum_{i + 1}^n <v_i, v_j> x_i * x_j$$, 也就是说每个特征对应一个"因子向量", 在做特征交叉时, 每一个新的组合特征的参数都由因子向量的内积得出, 这样就可以将新增参数的数量降为$$m*k$$, 其中$$k$$为因子向量的维度, 一般来说会比原始特征的数目要少。这就是为什么FM比LR做特征交叉的效率更高。

FM的核心思想就如上文所说的"特征交叉", 它可以作为回归模型、分类模型或排序模型来用, 分别可以对应于平方损失函数、hinge损失函数、pair-wise损失函数。在求解时可以用SGD进行求解, 实现来说的话, 只需要将损失函数的梯度表示出来, 就可以调用spark的optimizations模块来完成最优化求解, 从而求得模型参数。

