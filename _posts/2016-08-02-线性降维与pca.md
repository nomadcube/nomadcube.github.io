---
layout: post
tags: 机器学习
---

线性降维从线性代数的角度来看，是对原空间中的样本点做线性变换，得到在另一个低维子空间中的投影。又由线性变换矩阵中的各分量两两正交的性质可得，用作线性变换的矩阵相当于新的低维子空间的坐标系。因此可以看出，降维的关键在于求出做线性变换矩阵，即坐标系。

线性变换矩阵的形式取决于降维的目标。比如mds的目标是使得给定两个原样本点，它们之间的距离在降维前后保持不变，而pca的目标则是使得降维后最大程度在保留原样本包含的信息，同时样本点之间在新子空间中最大程度地分开。于是mds和pca算法最大的区别在于，前者对原样本集的距离矩阵做特征值分解，而后者对原样本集的协方差矩阵做特征集分解。


