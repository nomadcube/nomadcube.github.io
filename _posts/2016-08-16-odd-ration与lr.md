---
layout: post
tags: learning-to-rank
---

在包含离散变量的分类模型中，odd ratio可以用来衡量某个离散的自变量对因变量的影响。
记离散变量为$$X$$, 目标变量为$$Y$$, 简单又不失一般性地，假设两者的取值都是$${0,1}$$并且列联表如：

||1|0|
| -- | -- | -- |
|1|a|b|
|0|c|d|

这时候odd-ratio(X) = $$\frac{a/b}{c/d}$$, 即变量$$X$$存在时，目标变量取值为1的概率是$$X$$不存在时的$$\frac{a/b}{c/d}$$倍，从而也可看出$$X$$对目标变量$$Y$$的影响。直观上来讲，若odd-ratio(X)大于1，则影响是正向的，否则是负向的。

lr作为分类模型，独特之外在于它的模型假设是$$logit(p) = aX + b$$, 其中$$logit(p) = log(p/(1-p))$$, $$p$$为正样本概率。

从而可以推导出$$odd-ratio(X) = $$e^a$$, 推导过程如下：

1. 由logit函数的定义得，$$logit(p) = log(p/(1-p)) = aX + b$$
2. 当$$X = 1$$, $$p/(1-p) = e^{aX + b}$$
3. 当$$X = 0$$, $$p'/(1-p') = e^b$$
4. 综上，得$$\frac{p/(1-p)}{p'/(1-p')} = e^a$$

这和lr的参数解释也是一致的：$$a$$大于0时odd-ratio(X)也大于1，这两者同样意味着变量$$X$$的存在会使预测为正类别的概率增大。

想起这件事情是源于在用lr做隐式评分数据的推荐算法时，如果构造负样本时用的都是热门物品，那么最后推荐结果会极度偏向于非热门物品，因为任意一个热门物品作为lr的特征，由于这些特征的odd-ratio都小于1（因为a显著地比b小很多），因此只要是被选作构造负样本的热门物品，最终预测出来的概率值都比较低，从而也无法被排序到前面。
