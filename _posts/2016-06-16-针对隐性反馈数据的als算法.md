---
layout: post
tags: 推荐引擎
---

推荐算法的核心在于预测用户对物品的偏好，协同过滤是一簇只基于用户评分数据就可以完成这个预测的模型。

#### **协同过滤简介**

协同过滤分成两种：

1. neighborhood-based或者叫做memory-based
2. latent-factor-based或者叫model-based

前者包括itemCF和userCF, 是指使用基于某个特定用户的历史行为数据来预测他对其它物品的偏好分数，并且在这个过程中使用了"k近邻"的思想。比如itemCF预测用户$$u$$对物品$$i$$的分数时使用的公式是$$p(u, i) = \frac{\sum_{j \in S^k(i)} S_{ij}r_{uj}}{\sum_{j \in S^k(i)} S_{ij}}$$, 其中$$S^k(i)$$是指物品$$i$$的$$k$$个最近邻居。

后者比如SVD和ALS, 是指基于矩阵分解的思想，将评分矩阵分解成2个低秩矩阵，分别代表用户特征矩阵$$X$$和物品特征矩阵$$Y$$。在预测用户$$u$$对物品$$i$$的分数时，只需要将对应的向量$$X_u$$和$$Y_i$$做点积，而不需要$$u$$的历史行为数据。

#### **普通矩阵分解算法在隐性反馈数据上的问题**
矩阵分解一般使用平方损失函数，加上L2正则项。即经验损失函数为$$J(X,Y) = \sum_{u,i} ((r_{ui} - x_u^Ty_i)^2 + \lambda(x_ux_u^T + y_iy_i^T))$$. 对于推荐算法来说，不同的model-based算法最大的区别在于组成经验损失函数的$$(u,i)$$对的范围，以及各个$$(u,i)$$对的权重。比如SVD，它的经验损失函数只考虑原评分矩阵中的非零元素，而且各个元素的权重是一样的。

这对显性反馈数据来说是适用的，因为一般在显性反馈数据中，元素为零所代表的是用户对当前物品没有进行评分，或者他还没有发现当前物品的存在，因此并不包含任何偏好信息，可以作为缺失值来处理。

但隐性反馈数据相对显性反馈数据有三个特点：

1. 评分矩阵的元素值所代表的是"操作次数"，并不是"评分值"
2. 评分矩阵中的零元素产生的原因也可能是他还没有发现当前物品的存在，另外一些不可忽略的可能性是，他发现了这个物品，但由于不喜欢，因此没有做后续的交互操作。在这些情况下，就不可以将零元素当作缺失值处理了，因为它可能会包含偏好信息。
3. 评分矩阵中的非零元素并不是每一个所代表的偏好都一致，比如某用户对物品$$a$$和物品$$b$$都购买过，对应的元素值都是非零，但对$$a$$的购买次数更多，在这种情况下可以认为"更肯定用户喜欢物品$$b$$"

因此，适用于显性反馈数据的model-based推荐算法在隐性反馈数据中的表现不一定好。

#### **针对隐性反馈数据的ALS变式**
基本的ALS也是适用于显性反馈数据的，只不过是用交替最小二乘法（Alternating Least Square）而不是随机梯度下降来进行求解，这也是为什么它叫ALS的原因。

但针对隐性反馈数据的以上三个特点，ALS做了两个修正：

1. 将原评分矩阵中的零元素也考虑进去经验损失函数中
2. 各个元素对经验损失函数的贡献权重不一致，具体用confidence值来衡量

经过以上修正后，ALS的经验损失函数为：$$J(X,Y) = \sum_{u,i} (c_{ui}(p_{ui} - x_u^Ty_i)^2 + \lambda(x_ux_u^T + y_iy_i^T))$$，其中$$c_{ui} = 1 + \alpha r_{ui}$$就是confidence值。因此可以看到在原评分矩阵中元素值$$r_{ui}$$越大，confidence值就越大，也就是说，认为这个评分值更可信。同时，对于原评分矩阵中的零元素，confidence值为1，和非零元素之间的缩放比例取决于$$\alpha$$的大小。

因此，理论上来说，在隐性反馈数据上，这样的ALS变式表现会更好，但和所有的模型一样，它都有一些假设上或使用场景上的限制，比如更适用于"操作次数越多代表正反馈越强"的场景，比如电商上的购买、在线音乐的播放。但有时候操作次数越多并不一定代表更强的正反馈，比如应用商店的安装，特定用户对同一个应用多次下载背后隐含着一个事实是，这个用户对这个应用曾经有多次卸载行为。
