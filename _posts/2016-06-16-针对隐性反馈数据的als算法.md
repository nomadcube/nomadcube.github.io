---
layout: post
tags: 推荐算法
---

推荐算法的核心在于预测用户对物品的偏好。

#### **协同过滤简介**
协同过滤是一簇只基于用户评分数据就可以完成这个预测的模型，分成两种：

1. neighborhood-based或者叫做memory-based
2. latent-factor-based或者叫model-based

前者包括itemCF和userCF, 是指使用基于某个特定用户的历史行为数据来预测他对其它物品的偏好分数，并且在这个过程中使用了"k近邻"的思想。比如itemCF预测用户$$u$$对物品$$i$$的分数时使用的公式是$$p(u, i) = \frac{\sum_{j \in S^k(i)} S_{ij}r_{uj}}{\sum_{j \in S^k(i)} S_{ij}}$$, 其中$$S^k(i)$$是指物品$$i$$的$$k$$个最近邻居。

后者比如SVD和ALS, 是指基于矩阵分解的思想，将评分矩阵分解成2个低秩矩阵，分别代表用户特征矩阵$$X$$和物品特征矩阵$$Y$$。在预测用户$$u$$对物品$$i$$的分数时，只需要将对应的向量$$X_u$$和$$Y_i$$做点积，而不需要$$u$$的历史行为数据。

#### **普通矩阵分解算法在隐性反馈数据上的问题**
矩阵分解一般使用平方损失函数，加上L2正则项。即经验损失函数为$$J(X,Y) = \sum_{u,i} (r_{ui} - x_u^Ty_i)^2 + \lambda(x_ux_u^T + y_iy_i^T)$$. 对于推荐算法来说，不同的model-based算法最大的区别在于组成经验损失函数的$$(u,i)$$对的范围，以及各个$$(u,i)$$对的权重。比如SVD，它的经验损失函数只考虑原评分矩阵中的非零元素，而且各个元素的权重是一样的。

这对显性反馈数据来说是适用的，因为一般在显性反馈数据中，元素为零所代表的是用户对当前物品没有进行评分，或者他还没有发现当前物品的存在，因此并不包含任何偏好信息，可以作为缺失值来处理。

但隐性反馈数据相对显性反馈数据有两个特点：

1. 评分矩阵中的零元素产生的原因也可能是他还没有发现当前物品的存在，另外一些不可忽略的可能性是，他发现了这个物品，但由于不喜欢，因此没有做后续的交互操作。在这些情况下，就不可以将零元素当作缺失值处理了，因为它可能会包含偏好信息。
2. 评分矩阵中的非零元素并不是每一个所代表的偏好都一致，比如某用户对物品$$a$$和物品$$b$$都购买过，对应的元素值都是非零，但对$$a$$的购买次数更多，在这种情况下可以认为"更肯定用户喜欢物品$$b$$"。

针对以上两个特点，ALS做了两个修正：

1.

als的修正：1. 对负反馈的修正 2. 求解方法的优化，将算法复杂度降低到线性
als的推荐解释，和itemcf的整合
什么场景下适合用als
1. 操作次数越多表明正偏向越明显
