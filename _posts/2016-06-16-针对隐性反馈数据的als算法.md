---
layout: post
tags: 推荐算法
---

推荐算法的核心在于预测用户对物品的偏好。协同过滤是一簇只基于用户评分数据就可以完成这个预测的模型。

协同过滤分成两种：

1. neighborhood-based或者叫做memory-based
2. latent-factor-based或者叫model-based

前者包括itemCF和userCF, 是指使用基于某个特定用户的历史行为数据来预测他对其它物品的偏好分数，并且在这个过程中使用了"k近邻"的思想。比如itemCF预测用户$$u$$对物品$$i$$的分数时使用的公式是$$p(u, i) = \frac{\sum_{j \in S^k(i)} S_{ij}r_{uj}}{\sum_{j \in S^k(i)} S_{ij}}$$, 其中$$S^k(i)$$是指物品$$i$$的$$k$$个最近邻居。

后者比如SVD和ALS, 是指基于矩阵分解的思想，将评分矩阵分解成2个低秩矩阵，分别代表用户特征矩阵$$X$$和物品特征矩阵$$Y$$。在预测用户$$u$$对物品$$i$$的分数时，只需要将对应的向量$$X_u$$和$$Y_i$$做点积，而不需要$$u$$的历史行为数据。

矩阵分解一般使用平方损失函数，加上L2正则项。即经验损失函数为$$J(X,Y) = \sum_{u,i} (r_{ui} - x_u^Ty_i)^2 + \lambda(x_ux_u^T + y_iy_i^T)$$.

对于推荐算法来说，不同的model-based算法最大的区别在于组成经验损失函数的$$(u,i)$$对的范围，以及各个$$(u,i)$$对的权重。

比如SVD，它的经验损失函数只考虑原评分矩阵中的非零元素，而且各个元素的权重是一样的。



svd的假设，损失函数，求解方法
svd的假设和损失函数在隐性反馈数据集上的缺陷
在隐性反馈数据集的关键要解决的问题：负反馈的损失函数不足以代表真实情况
als的修正：1. 对负反馈的修正 2. 求解方法的优化，将算法复杂度降低到线性
als的推荐解释，和itemcf的整合
什么场景下适合用als
