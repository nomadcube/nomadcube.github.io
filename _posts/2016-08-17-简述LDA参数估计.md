---
layout: post
tags: 矩阵分解 贝叶斯统计
---

LDA最主要的参数是主题-词条矩阵。回想LDA的模型假设，它认为主题是关于词条的多项式分布，若语料中共有$$K$$个主题，那么就相应地有$$K$$个不同的多项式分布。若语料中共有$$V$$个词，那么这$$K$$个多项式分布总共有$$KV$$个参数，这就是所谓的"主题-词条矩阵"，记为$$\beta = (\vec p_1, ..., \vec p_K)$$

根据贝叶斯统计的思想，要估计$$\beta$$, 需要3个要素：先验分布、似然函数、后验分布：

1. 先验分布，在这里指的是每一个主题的多项式分布参数，以第k个主题为例，即$$\vec p_k = (p_{k,1}, p_{k,2}, ..., p_{k,V})$$所服从的分布，记为$$prior(\vec p_k)$$. 

2. 似然函数是指假设参数已知的前提下，数据的出现概率，即$$P(X;\beta)$$, 这里指的是已知各个主题在词条上的分布参数时，计算出各个主题由所观测到的词条所组成的概率

3. 后验分布，即先验分布和似然函数的乘积，是一个关于$$\beta$$的函数

这和普通的贝叶斯统计框架并无差异，最简单的例子见[伯努利分布的贝叶斯参数估计](https://nomadcube.github.io/2017/04/04/%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83%E7%9A%84%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/).

LDA的特别在于它的先验分布。在[伯努利分布的贝叶斯参数估计](https://nomadcube.github.io/2017/04/04/%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83%E7%9A%84%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/)中可以看到设置的先验分布是离散分布，而对应的后验分布也是一个普通的离散分布，通过枚举就可以求得极大值解。而LDA的精妙之处是用狄利克雷分布作为先验分布，这样的好处是使得后验分布也是一个狄利克雷分布，只不过参数被似然函数修正过。

LDA有这样的性质主要是因为这个事实：狄利克雷分布和多项分布的乘积也是一个狄利克雷分布。这从直觉上理解是很简单的。

不妨退化到二维的情况下作类比：在二维的情况下，狄利克雷分布退化成Beta分布，记为$$Beta(\alpha, \beta)$$. 要注意这里的$$\beta$$仅作一个记号，含义并不是上文所指的LDA参数。Beta分布代表的物理意义也很直接：一个只有2种可能性的事件，成功的概率是$$\frac{\alpha}{\alpha + \beta}$$. 而多项分布退化到二维则是一个二项分布，只有成功或失败两种可能。对于n次试验而言，若成功了a次，失败了b次，那么后验分布就更新为$$Beta(\alpha + a, \beta + b)$$. 

而$$\alpha$$和$$\beta$$作为先验分布的参数，在建模时是需要人工设定的。贝叶斯学派的一个思想是，对模型参数的估计不完全依赖于观测数据，主观经验也会有影响，而主观经验的表现形式则是先验分布，如果认为人的经验在当前的问题中并不充分，那么可以将先验分布设为近似于均匀分布；如果认为人的经验已经很成熟，那么可以将经验所认为的情况用先验分布的形式表现出来，最极端的例子是，以伯努利分布作为先验分布，假如人的经验很有把握地认为是1的可能性最大，那么先验分布就可以设成类似$$(0.9, 0.1)$$这样的比例。先验分布为狄利克雷分布也是一样的，当经验不足时可以设成更"均匀"的狄利克雷分布，即$$\alpha$$接近于1。

LDA是层次贝叶斯模型, 包含文档-主题、主题-词条两层, 其中主题是隐变量, 词条是观测变量, 文档生成主题、主题生成词条分别服从参数为$$\Theta, \Phi$$的多项式分布, 而这些多项式分布的先验分布分别是参数为$$\alpha, \beta$$的dirichlet分布。

LDA主要是两个问题: 参数估计、贝叶斯推断。

参数估计是指估计后验分布的超参数, 即$$\alpha', \beta'$$。思路也是求对数似然函数的极大值点。

贝叶斯推断是指已知超参数$$\alpha', \beta'$$的前提下, 对任意一篇文档, 估计它的主题分布。这相当于是求解由文档生成主题的多项式分布参数, 由于生成过程涉及隐变量, 因此求解时需要用到EM算法, 而在EM算法的E步时可以利用DIRICHLET分布的性质方便地求期望。

在《beta先验分布》中提到了传说中的beta分布, 当beta分布中的$$x$$从标量扩展到多维向量时, beta分布也可扩展为Dirichlet分布。换言之, Dirichlet分布是beta分布在多维上的扩展。因此两者性质也比较接近, 比如:

1. 当beta分布的2个参数相等, 即$$\alpha = \beta$$时, beta分布是对称分布。对Dirichlet分布来说也一样, 当参数$$\alpha_1, ..., \alpha_k$$都相等时, 这样的Dirichlet分布也称为对称Dirichlet分布, 从几何上来看是呈对称形态的。

2. 当beta分布的2个参数同时等于1时, beta分布退化为均匀分布。当Dirichlet分布的参数$$\alpha_1, ..., \alpha_k$$都等于1时, 同样也退化为高维空间上的均匀分布。

beta分布的物理意义是表示一组均匀分布的观测数据中某个顺序统计量的分布, 因而Dirichlet分布也类似地看成是同样条件下多个顺序统计量的联合概率密度分布。

比较常用的是对称Dirichlet分布, 即参数向量的分量都相等。这时候各分量的值也称为concentrate值。当concentrate值大于1时, 对称Dirichlet分布相对"密集", 即来自这个分布的一条观测向量之间的分量集中在某个值的可能性比较大, 当concentrate值小于1时则相反,观测向量中很可能某个分量出现的概率接近1, 其它的接近0. 但需要留意的一点是, 目前在SPARK1.6.2版本实现的LDA中, 将concentrate值限定为大于1, 具体原因尚待探讨。

### gamma函数
gamma函数是阶乘在复数集上的扩展, 因此当$$n$$为正整数时, $$\Gamma(n) = n!$$。

### B函数
B函数也称为beta函数, 和gamma函数的关系: $$B(\alpha, \beta) = \frac{\Gamma(\alpha) \Gamma(\beta)}{\Gamma(\alpha + \beta)}$$。

### beta分布
beta分布的常数项由B函数构成, 概率密度函数为$$f(x; \alpha, \beta) = \frac{1}{B(\alpha, \beta)} x^{\alpha-1}(1-x)^{\beta-1}$$

### 贝叶斯定理
在离散先验分布下, 贝叶斯定理可以表示为$$P(A|B) = \frac{P(B|A)P(A)}{\sum_{i} P(B|A_i)P(A_i)}$$。在连续先验分布下表示为$$f(x|y) = \frac{f(y|x)f(x)}{\int f(y|x)f(x) dx}$$.

### 二项分布、beta分布和共轭
当先验分布为beta分布, 数据分布服从二项分布, 后验分布同样为beta分布, 这时beta分布也称为二项分布的共轭分布。推导如下:

1. 二项分布的参数$$\theta ~ beta(\alpha, \beta)$$, 即$$f(\theta) = \frac{\Gamma(\alpha) \Gamma(\beta)}{\Gamma(\alpha + \beta)} \theta^{\alpha-1}(1-\theta)^{\beta-1}$$

2. 观测数据服从二项分布, 即$$X ~ Binomial(\theta)$$, 于是$$X$$的似然函数为$$L(X;\theta) = C_{n}^{s} \theta^s (1 - \theta)^{(n - s)}$$, 其中$$n, s$$分别代表试验次数和成功次数

3. 在以上两个假设下, 后验分布的密度函数为$$f(\theta;X) = \frac{f(X;\theta)f(\theta)}{\int f(X;\theta)f(\theta) d(\theta)}$$, 其中$$f(X;\theta)f(\theta) = \frac{\Gamma(\alpha) \Gamma(\beta)}{\Gamma(\alpha + \beta)} C_{n}^{s} \theta^{s + \alpha-1} (1 - \theta)^(n - s + \beta-1)$$, 代入后验分布的密度函数并约去常数项$$\frac{\Gamma(\alpha) \Gamma(\beta)}{\Gamma(\alpha + \beta)} C_{n}^{s}$$后, $$f(\theta;X) = \frac{\theta^{s + \alpha-1} (1 - \theta)^(n - s + \beta-1)}{\int \theta^{s + \alpha-1} (1 - \theta)^(n - s + \beta-1) d\theta}$$, 这正是beta分布的形式, 参数分别为$$s + \alpha, n-s+\beta$$, 因此后验分布服从beta分布$$beta(s + \alpha, n-s+\beta)$$.

另一个事实是, beta分布的均值为$$\frac{\alpha}{\alpha + \beta}$$, 因此当观测数据将先验beta分布的均值向左或右"拉", 处于先验分布和后验分布均值之间, 相当于使得后验分布同时符合先验知识和观测数据所表达的信息。

